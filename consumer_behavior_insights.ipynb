{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73d48b3-f57b-460a-917c-47137a6f9354",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "#  Pandas library\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6f5a27-7ce0-43ad-b48b-8e429320f5e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   Customer ID        Purchase Date Product Category  Product Price  Quantity  \\\n",
      "0        44605  2023-05-03 21:30:02             Home            177         1   \n",
      "1        44605  2021-05-16 13:57:44      Electronics            174         3   \n",
      "2        44605  2020-07-13 06:16:57            Books            413         1   \n",
      "3        44605  2023-01-17 13:14:36      Electronics            396         3   \n",
      "4        44605  2021-05-01 11:29:27            Books            259         4   \n",
      "\n",
      "   Total Purchase Amount Payment Method  Customer Age  Returns Customer Name  \\\n",
      "0                   2427         PayPal            31      1.0   John Rivera   \n",
      "1                   2448         PayPal            31      1.0   John Rivera   \n",
      "2                   2345    Credit Card            31      1.0   John Rivera   \n",
      "3                    937           Cash            31      0.0   John Rivera   \n",
      "4                   2598         PayPal            31      1.0   John Rivera   \n",
      "\n",
      "   Age  Gender  Churn  \n",
      "0   31  Female      0  \n",
      "1   31  Female      0  \n",
      "2   31  Female      0  \n",
      "3   31  Female      0  \n",
      "4   31  Female      0  \n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the large dataset\n",
    "file_path = \"C:\\\\Users\\\\Azalas12\\\\Desktop\\\\E-commerce Customer Data For Behavior Analysis\\\\ecommerce_customer_data_large.csv\"\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows to confirm it loaded correctly\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa3b0708-269c-4d15-90e9-4ceb1ebc8ea9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame Information ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Customer ID            250000 non-null  int64  \n",
      " 1   Product Category       250000 non-null  object \n",
      " 2   Product Price          250000 non-null  int64  \n",
      " 3   Quantity               250000 non-null  int64  \n",
      " 4   Total Purchase Amount  250000 non-null  int64  \n",
      " 5   Payment Method         250000 non-null  object \n",
      " 6   Customer Age           250000 non-null  int64  \n",
      " 7   Returns                250000 non-null  float64\n",
      " 8   Customer Name          250000 non-null  object \n",
      " 9   Age                    250000 non-null  int64  \n",
      " 10  Gender                 250000 non-null  object \n",
      " 11  Churn                  250000 non-null  int64  \n",
      " 12  recency                250000 non-null  int64  \n",
      " 13  frequency              250000 non-null  int64  \n",
      " 14  monetary_value         250000 non-null  int64  \n",
      "dtypes: float64(1), int64(10), object(4)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning and Preparation\n",
    "# Check for a comprehensive overview of the DataFrame, including data types and non-null values\n",
    "# This helps us quickly identify columns with missing data\n",
    "print(\"--- DataFrame Information ---\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d2b63d-a6b9-4d81-a420-00b342961a42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Number of Duplicate Rows ---\n",
      "Total duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows across the entire dataset\n",
    "# The .sum() method will count the number of True values, telling us how many duplicates there are\n",
    "print(\"\\n--- Number of Duplicate Rows ---\")\n",
    "print(f\"Total duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814c9898-6acf-4bf3-a035-1107d222c297",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Values After Imputation ---\n",
      "Customer ID              0\n",
      "Purchase Date            0\n",
      "Product Category         0\n",
      "Product Price            0\n",
      "Quantity                 0\n",
      "Total Purchase Amount    0\n",
      "Payment Method           0\n",
      "Customer Age             0\n",
      "Returns                  0\n",
      "Customer Name            0\n",
      "Age                      0\n",
      "Gender                   0\n",
      "Churn                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in the 'Returns' column with 0\n",
    "# The 'inplace=True' argument modifies the DataFrame directly without creating a new one\n",
    "df['Returns'] = df['Returns'].fillna(0)\n",
    "\n",
    "# Confirm that the missing values have been filled\n",
    "# The .isnull().sum() method is a quick way to count missing values per column\n",
    "print(\"--- Missing Values After Imputation ---\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47780420-cc06-4add-9d8a-a4ccf9b79151",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame Information After Date Conversion ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   Customer ID            250000 non-null  int64         \n",
      " 1   Purchase Date          250000 non-null  datetime64[ns]\n",
      " 2   Product Category       250000 non-null  object        \n",
      " 3   Product Price          250000 non-null  int64         \n",
      " 4   Quantity               250000 non-null  int64         \n",
      " 5   Total Purchase Amount  250000 non-null  int64         \n",
      " 6   Payment Method         250000 non-null  object        \n",
      " 7   Customer Age           250000 non-null  int64         \n",
      " 8   Returns                250000 non-null  float64       \n",
      " 9   Customer Name          250000 non-null  object        \n",
      " 10  Age                    250000 non-null  int64         \n",
      " 11  Gender                 250000 non-null  object        \n",
      " 12  Churn                  250000 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(7), object(4)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Purchase Date' column to a datetime object\n",
    "df['Purchase Date'] = pd.to_datetime(df['Purchase Date'])\n",
    "\n",
    "# Confirm the change by checking the DataFrame information again\n",
    "print(\"--- DataFrame Information After Date Conversion ---\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143c7dfc-59e9-4de6-a409-6d64c649e17b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency DataFrame:\n",
      "   Customer ID       Purchase Date  recency\n",
      "0            1 2022-11-29 06:48:25      289\n",
      "1            2 2023-07-03 17:26:19       73\n",
      "2            3 2023-02-03 03:58:07      223\n",
      "3            4 2022-06-29 03:41:09      442\n",
      "4            5 2022-07-16 04:08:09      425\n"
     ]
    }
   ],
   "source": [
    "# Calculate (RECENCY) the most recent date in the dataset to use as a reference point\n",
    "current_date = df['Purchase Date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# Group the DataFrame by 'Customer ID' and find the maximum (most recent) 'Purchase Date' for each customer.\n",
    "# Then, subtract that date from our 'current_date' to get the recency in days.\n",
    "recency_df = df.groupby('Customer ID')['Purchase Date'].max().reset_index()\n",
    "recency_df['recency'] = (current_date - recency_df['Purchase Date']).dt.days\n",
    "\n",
    "# Display the new DataFrame with customer ID and recency\n",
    "print(\"Recency DataFrame:\")\n",
    "print(recency_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a741088f-f72d-4d87-9005-1bef0c611a88",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency and Monetary Value DataFrame:\n",
      "   Customer ID  frequency  monetary_value\n",
      "0            1          3            6290\n",
      "1            2          6           16481\n",
      "2            3          4            9423\n",
      "3            4          5            7826\n",
      "4            5          5            9769\n"
     ]
    }
   ],
   "source": [
    "# Calculating FREQUENCY and MONETARY VALUE \n",
    "# Group by 'Customer ID' and use a dictionary inside .agg() to apply different aggregations to different columns.\n",
    "# We'll count the number of rows for Frequency and sum the 'Total Purchase Amount' for Monetary Value.\n",
    "rfm_df = df.groupby('Customer ID').agg(\n",
    "    frequency=('Customer ID', 'size'),\n",
    "    monetary_value=('Total Purchase Amount', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Display the new DataFrame with Frequency and Monetary Value\n",
    "print(\"\\nFrequency and Monetary Value DataFrame:\")\n",
    "print(rfm_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afecf1c2-db2b-4fa0-b63e-27c4b538dee5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Master DataFrame with Recency, Frequency, and Monetary Value:\n",
      "   Customer ID       Purchase Date  recency  frequency  monetary_value\n",
      "0            1 2022-11-29 06:48:25      289          3            6290\n",
      "1            2 2023-07-03 17:26:19       73          6           16481\n",
      "2            3 2023-02-03 03:58:07      223          4            9423\n",
      "3            4 2022-06-29 03:41:09      442          5            7826\n",
      "4            5 2022-07-16 04:08:09      425          5            9769\n"
     ]
    }
   ],
   "source": [
    "# Merge the recency and rfm DataFrames based on 'Customer ID'\n",
    "master_df = pd.merge(recency_df, rfm_df, on='Customer ID')\n",
    "\n",
    "# Display the final master DataFrame with all the new features\n",
    "print(\"\\nMaster DataFrame with Recency, Frequency, and Monetary Value:\")\n",
    "print(master_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee901adb-a7e6-4529-9786-9879fff9bcc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame after merging new features:\n",
      "   Customer ID Product Category  Product Price  Quantity  \\\n",
      "0        44605             Home            177         1   \n",
      "1        44605      Electronics            174         3   \n",
      "2        44605            Books            413         1   \n",
      "3        44605      Electronics            396         3   \n",
      "4        44605            Books            259         4   \n",
      "\n",
      "   Total Purchase Amount Payment Method  Customer Age  Returns Customer Name  \\\n",
      "0                   2427         PayPal            31      1.0   John Rivera   \n",
      "1                   2448         PayPal            31      1.0   John Rivera   \n",
      "2                   2345    Credit Card            31      1.0   John Rivera   \n",
      "3                    937           Cash            31      0.0   John Rivera   \n",
      "4                   2598         PayPal            31      1.0   John Rivera   \n",
      "\n",
      "   Age  Gender  Churn  recency  frequency  monetary_value  \n",
      "0   31  Female      0      133          5           10755  \n",
      "1   31  Female      0      133          5           10755  \n",
      "2   31  Female      0      133          5           10755  \n",
      "3   31  Female      0      133          5           10755  \n",
      "4   31  Female      0      133          5           10755  \n"
     ]
    }
   ],
   "source": [
    "# Merge the 'master_df' with the original 'df' DataFrame\n",
    "# We'll use a 'left' merge to keep all the original rows from 'df'\n",
    "# The 'on' argument specifies the common column to merge on\n",
    "df = pd.merge(df, master_df[['Customer ID', 'recency', 'frequency', 'monetary_value']], on='Customer ID', how='left')\n",
    "\n",
    "# Drop the 'Purchase Date' from the merged master_df as it is now redundant\n",
    "df.drop('Purchase Date', axis=1, inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the final DataFrame to show the new columns\n",
    "print(\"Final DataFrame after merging new features:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf7e3e6-db36-489b-8661-d88014e99857",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RFM values for Churned (1) vs. Non-Churned (0) customers:\n",
      "          recency  frequency  monetary_value\n",
      "Churn                                       \n",
      "0      218.226953   5.991695    16321.589413\n",
      "1      216.314881   6.008298    16373.152982\n"
     ]
    }
   ],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "# Comparing the average recency, frequency, and monetary_value for customers who churned versus those who did not\n",
    "# Group the DataFrame by the 'Churn' column and calculate the mean for each group\n",
    "# We'll focus on our three new features: recency, frequency, and monetary_value\n",
    "eda_results = df.groupby('Churn')[['recency', 'frequency', 'monetary_value']].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Average RFM values for Churned (1) vs. Non-Churned (0) customers:\")\n",
    "print(eda_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9588f1ac-5ad7-4efe-bfa9-70bf0cbd4fc9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Rate by Product Category:\n",
      "  Product Category     Churn\n",
      "1         Clothing  0.201227\n",
      "0            Books  0.200797\n",
      "2      Electronics  0.200431\n",
      "3             Home  0.199626\n"
     ]
    }
   ],
   "source": [
    "# Digging deeper\n",
    "# Group the DataFrame by 'Product Category' and calculate the mean of the 'Churn' column.\n",
    "# The mean of a 0/1 (no churn/churn) column gives us the churn rate.\n",
    "category_churn_rate = df.groupby('Product Category')['Churn'].mean().reset_index()\n",
    "\n",
    "# Sort the results in descending order to easily see which categories have the highest churn rate\n",
    "category_churn_rate.sort_values(by='Churn', ascending=False, inplace=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"Churn Rate by Product Category:\")\n",
    "print(category_churn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07705203-b189-413b-a541-5529da3f3ab8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Rate by Gender:\n",
      "   Gender     Churn\n",
      "0  Female  0.201626\n",
      "1    Male  0.199426\n",
      "\n",
      "-----------------------\n",
      "\n",
      "Churn Rate by Payment Method:\n",
      "  Payment Method     Churn\n",
      "0           Cash  0.202525\n",
      "2         PayPal  0.202430\n",
      "1    Credit Card  0.196620\n"
     ]
    }
   ],
   "source": [
    "# Digging more deep for insights → Gender and Churn & Payment Method and Churn\n",
    "# Group the DataFrame by 'Gender' and calculate the mean of the 'Churn' column.\n",
    "gender_churn_rate = df.groupby('Gender')['Churn'].mean().reset_index()\n",
    "\n",
    "# Sort the results\n",
    "gender_churn_rate.sort_values(by='Churn', ascending=False, inplace=True)\n",
    "print(\"Churn Rate by Gender:\")\n",
    "print(gender_churn_rate)\n",
    "\n",
    "print(\"\\n-----------------------\\n\")\n",
    "\n",
    "# Group the DataFrame by 'Payment Method' and calculate the mean of the 'Churn' column.\n",
    "payment_method_churn_rate = df.groupby('Payment Method')['Churn'].mean().reset_index()\n",
    "\n",
    "# Sort the results\n",
    "payment_method_churn_rate.sort_values(by='Churn', ascending=False, inplace=True)\n",
    "print(\"Churn Rate by Payment Method:\")\n",
    "print(payment_method_churn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0be0037-53f6-41fd-b07b-30365061c123",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Rate by Age Group:\n",
      "  Age_Group     Churn\n",
      "0     18-24  0.210725\n",
      "5     65-74  0.205667\n",
      "4     55-64  0.201225\n",
      "2     35-44  0.198850\n",
      "1     25-34  0.198557\n",
      "3     45-54  0.192921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azalas12\\AppData\\Local\\Temp\\ipykernel_26708\\805273779.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  age_group_churn = df.groupby('Age_Group')['Churn'].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Going even deeper through age grouping against churn\n",
    "# Define age ranges for our bins\n",
    "age_bins = [18, 25, 35, 45, 55, 65, 75]\n",
    "labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65-74']\n",
    "\n",
    "# Create a new column 'Age_Group' by binning the 'Customer Age' column\n",
    "df['Age_Group'] = pd.cut(df['Customer Age'], bins=age_bins, labels=labels, right=False)\n",
    "\n",
    "# Group by the new 'Age_Group' and calculate the mean churn rate for each group\n",
    "age_group_churn = df.groupby('Age_Group')['Churn'].mean().reset_index()\n",
    "\n",
    "# Sort the results in descending order to easily see which age groups have the highest churn rate\n",
    "age_group_churn.sort_values(by='Churn', ascending=False, inplace=True)\n",
    "\n",
    "print(\"Churn Rate by Age Group:\")\n",
    "print(age_group_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a4ab42c-1095-4ad6-b82a-dbf73b1cec20",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Combinations by Churn Rate:\n",
      "   Product Category Monetary_Group Frequency_Group     Churn\n",
      "18            Books           50K+           11-15  1.000000\n",
      "78             Home           50K+           11-15  1.000000\n",
      "58      Electronics           50K+           11-15  1.000000\n",
      "38         Clothing           50K+           11-15  1.000000\n",
      "10            Books        10K-20K           11-15  0.306011\n",
      "30         Clothing        10K-20K           11-15  0.300493\n",
      "50      Electronics        10K-20K           11-15  0.263441\n",
      "61             Home           0-5K            6-10  0.214286\n",
      "4             Books         5K-10K             1-5  0.207668\n",
      "24         Clothing         5K-10K             1-5  0.206669\n",
      "\n",
      "Bottom 10 Combinations by Churn Rate:\n",
      "   Product Category Monetary_Group Frequency_Group  Churn\n",
      "56      Electronics           50K+             1-5    NaN\n",
      "57      Electronics           50K+            6-10    NaN\n",
      "62             Home           0-5K           11-15    NaN\n",
      "63             Home           0-5K             16+    NaN\n",
      "66             Home         5K-10K           11-15    NaN\n",
      "67             Home         5K-10K             16+    NaN\n",
      "71             Home        10K-20K             16+    NaN\n",
      "72             Home        20K-50K             1-5    NaN\n",
      "76             Home           50K+             1-5    NaN\n",
      "77             Home           50K+            6-10    NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azalas12\\AppData\\Local\\Temp\\ipykernel_26708\\938175152.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  combined_analysis = df.groupby(['Product Category', 'Monetary_Group', 'Frequency_Group'])['Churn'].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Create bins for 'monetary_value'\n",
    "monetary_bins = [0, 5000, 10000, 20000, 50000, 100000]\n",
    "monetary_labels = ['0-5K', '5K-10K', '10K-20K', '20K-50K', '50K+']\n",
    "df['Monetary_Group'] = pd.cut(df['monetary_value'], bins=monetary_bins, labels=monetary_labels, right=False)\n",
    "\n",
    "# Create bins for 'frequency' - Fixed to ensure monotonic increase\n",
    "max_freq = df['frequency'].max()\n",
    "# Check if max frequency is greater than our last defined bin\n",
    "if max_freq <= 20:\n",
    "    # If max is 20 or less, adjust the bins to ensure they increase\n",
    "    frequency_bins = [0, 5, 10, 15, max_freq]\n",
    "    frequency_labels = ['1-5', '6-10', '11-15', '16+']\n",
    "else:\n",
    "    # Original bins if max frequency is greater than 20\n",
    "    frequency_bins = [0, 5, 10, 15, 20, max_freq]\n",
    "    frequency_labels = ['1-5', '6-10', '11-15', '16-20', '20+']\n",
    "\n",
    "df['Frequency_Group'] = pd.cut(df['frequency'], bins=frequency_bins, labels=frequency_labels, right=False)\n",
    "\n",
    "# Group by the three features and calculate the mean of 'Churn'\n",
    "combined_analysis = df.groupby(['Product Category', 'Monetary_Group', 'Frequency_Group'])['Churn'].mean().reset_index()\n",
    "\n",
    "# Sort the results by churn rate to see the highest and lowest combinations\n",
    "combined_analysis.sort_values(by='Churn', ascending=False, inplace=True)\n",
    "\n",
    "print(\"Top 10 Combinations by Churn Rate:\")\n",
    "print(combined_analysis.head(10))\n",
    "\n",
    "print(\"\\nBottom 10 Combinations by Churn Rate:\")\n",
    "print(combined_analysis.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfbda817-5f5f-4d9a-bd7c-bebe16c209d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Save the final DataFrame to a CSV file\n",
    "df.to_csv('customer_churn_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6216df07-9924-4e6f-b695-d8949053d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.path.exists('customer_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a3edd-8925-49bd-a738-70f866eb08de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
